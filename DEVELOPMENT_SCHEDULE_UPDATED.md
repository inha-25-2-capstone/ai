# 개발 일정 (수정판 - 자동 라벨링 적용)

**프로젝트 기간:** 11/4 ~ 12/15 (총 5주)
**시연/발표:** 12/15
**팀 구성:** 2-3명 (프론트/백엔드/AI 분담)

**✨ 주요 변경:** LLM 자동 라벨링 도입으로 **Week 1 일정 대폭 단축!**

---

## 📊 전체 타임라인 요약

| Week | 주요 작업 | 완료 기준 |
|------|----------|----------|
| **Week 1** (11/4-11/10) | 데이터 수집 + 자동 라벨링 + 검수 | 6000개 라벨링 완료 |
| **Week 2** (11/11-11/17) | 모델 학습 + 백엔드 API 기본 구현 | 모델 정확도 75%+ |
| **Week 3** (11/18-11/24) | AI-백엔드 연동 + 프론트 연동 | E2E 연결 완료 |
| **Week 4** (11/25-12/1) | 통합 테스트 + 버그 수정 | 전체 시스템 동작 |
| **Week 5** (12/2-12/15) | 시연 준비 + 발표 자료 | 발표 준비 완료 |

---

## 📅 Week 1: 데이터 준비 (11/4-11/10) ⚡ 대폭 단축!

### Day 1-2 (11/4-11/5): 뉴스 수집
```
□ 11/4 (오전): 토픽 선정
  - 정치 이슈 5-7개 선정
  - 예: 부동산 정책, 노동 정책, 외교, 교육, 환경 등

□ 11/4 (오후): 수집 방법 결정
  - Naver API 또는 크롤링
  - scripts/collect_news.py 활용

□ 11/5 (전일): 뉴스 수집
  - 목표: 6000개 수집 (토픽당 1000개)
  - 저장: data/unlabeled_6000.csv
```

**담당:** 전체 팀원 (토픽별로 분담)

---

### Day 3-4 (11/6-11/7): 자동 라벨링 ⚡ 핵심!

```
□ 11/6 (오전): API 키 발급 및 테스트
  - Gemini API 키 발급 (무료)
  - ChatGPT API 키 발급 (옵션)
  - 샘플 10개로 테스트:
    python scripts/auto_labeling.py --sample 10

□ 11/6 (오후): 배치 1000개 라벨링
  - 첫 1000개 라벨링 (약 10-15분)
  - 결과 확인 및 프롬프트 조정 필요 시 수정

□ 11/7 (전일): 전체 6000개 자동 라벨링
  - Gemini로 6000개 라벨링 (약 1시간)
  - 또는 ChatGPT + Gemini 교차 검증 (약 2시간)
  - 중간 저장 활성화 (100개마다)

  명령어:
  python scripts/auto_labeling.py \
    --input data/unlabeled_6000.csv \
    --output data/auto_labeled_6000.csv \
    --provider gemini \
    --gemini-key YOUR_KEY \
    --save-interval 100
```

**담당:** AI 담당자 1명

**예상 소요:**
- API 키 발급: 30분
- 테스트: 30분
- 전체 라벨링: 1-2시간
- **총 3-4시간 (기존 대비 90% 단축!)**

---

### Day 5-7 (11/8-11/10): 검수 및 검증

```
□ 11/8 (전일): 검수 대상 필터링
  - 신뢰도 < 0.7 샘플 추출 (예상: 600-1200개)
  - 또는 API 불일치 샘플 추출 (예상: 300-900개)

  명령어:
  python scripts/review_labels.py \
    --input data/auto_labeled_6000.csv \
    --output data/reviewed.csv \
    --low-confidence

□ 11/9-11/10 (2일): 팀원 분담 검수
  - 2-3명이 나눠서 검수 (1인당 200-400개)
  - 하루 3-4시간 집중 작업
  - 대화형 도구로 빠르게 검수

□ 11/10 (오후): 최종 검증
  - 데이터 검증 스크립트 실행
  - 클래스 분포 확인
  - 최종 데이터셋 저장: data/final_labeled_6000.csv

  명령어:
  python scripts/validate_data.py --input data/final_labeled_6000.csv
```

**담당:** 전체 팀원 분담

**검수 예상:**
- 필터링: 30분
- 검수 (600개, 3명 분담): 각 2-3시간
- 검증: 30분
- **총 3-4시간 (팀 분담 시)**

---

### Week 1 목표 달성 기준 ✅

- [x] 6000개 뉴스 수집 완료
- [x] 자동 라벨링 완료 (신뢰도 포함)
- [x] 600-1000개 검수 완료
- [x] 클래스 분포 균형 확인 (최대/최소 비율 3:1 이하)
- [x] 데이터 품질 검증 통과

**🎯 Week 1 총 소요 시간: 2-3일 (기존 7일 → 70% 단축!)**

---

## 📅 Week 2: 모델 학습 + 백엔드 기본 API (11/11-11/17)

### AI 파트 (11/11-11/17)

```
□ 11/11 (1일): 데이터 전처리 및 분할
  - Train/Val/Test 분할 (70/10/20)
  - Colab 노트북에 업로드
  - 토크나이저 테스트

□ 11/12-11/14 (3일): Few-shot 학습
  - KoBERT Few-shot 학습 (전체 6000개 중 일부 사용)
  - 하이퍼파라미터 튜닝
  - 목표: 75% 이상 정확도

□ 11/15-11/17 (3일): 파인튜닝 및 최적화
  - 전체 데이터로 파인튜닝
  - 모델 성능 개선
  - 목표: 80-85% 정확도
  - 모델 저장: saved_models/stance_classifier_final.pth
```

**담당:** AI 담당자

---

### 백엔드 파트 (11/11-11/17)

```
□ 11/11-11/12 (2일): API 설계
  - 뉴스 분석 API 스펙 정의
  - DB 스키마 설계
    - News 테이블 (id, text, source, date, topic)
    - Analysis 테이블 (id, news_id, stance, confidence, created_at)
  - Swagger 문서 작성

□ 11/13-11/15 (3일): 기본 CRUD API 구현
  - POST /api/news - 뉴스 등록
  - GET /api/news/{id} - 뉴스 조회
  - GET /api/news - 뉴스 목록
  - DB 연동 (PostgreSQL/SQLite)

□ 11/16-11/17 (2일): API 테스트
  - Postman으로 API 테스트
  - 에러 핸들링 추가
  - CORS 설정
```

**담당:** 백엔드 담당자

---

### Week 2 목표 달성 기준 ✅

- [x] 모델 학습 완료 (정확도 75% 이상)
- [x] 모델 저장 완료
- [x] 백엔드 기본 CRUD API 완료
- [x] DB 연동 완료

---

## 📅 Week 3: AI-백엔드 연동 + 프론트 연동 (11/18-11/24)

### AI 서버 파트 (11/18-11/20)

```
□ 11/18 (1일): 모델 통합
  - 학습된 모델을 AI 서버에 적용
  - main.py에서 모델 로드 테스트
  - 성능 측정 (응답 시간)

□ 11/19-11/20 (2일): API 개선
  - 에러 핸들링 강화
  - 배치 처리 추가 (여러 뉴스 동시 분석)
  - 로깅 및 모니터링
```

**담당:** AI 담당자

---

### 백엔드 파트 (11/18-11/21)

```
□ 11/18-11/19 (2일): AI 서버 연동 API
  - POST /api/analyze - AI 서버에 분석 요청
  - AI 서버 HTTP 클라이언트 구현
  - 응답 파싱 및 DB 저장

□ 11/20-11/21 (2일): 추가 API 구현
  - GET /api/analysis/{news_id} - 분석 결과 조회
  - GET /api/analysis - 분석 결과 목록
  - 필터링 (스탠스별, 날짜별)
```

**담당:** 백엔드 담당자

---

### 프론트엔드 파트 (11/18-11/24)

```
□ 11/18-11/19 (2일): API 클라이언트 설정
  - Axios 설정
  - API 엔드포인트 환경 변수
  - Mock 데이터로 UI 테스트

□ 11/20-11/22 (3일): 기본 기능 구현
  - 뉴스 입력 폼
  - 분석 요청 버튼
  - 결과 표시 (스탠스, 신뢰도)
  - 로딩/에러 UI

□ 11/23-11/24 (2일): 실제 API 연동
  - 백엔드 API 연동
  - E2E 테스트 (뉴스 입력 → 분석 → 결과 표시)
  - UI/UX 개선
```

**담당:** 프론트엔드 담당자

---

### Week 3 목표 달성 기준 ✅

- [x] AI 서버에 실제 모델 적용 완료
- [x] 백엔드 - AI 서버 연동 완료
- [x] 프론트엔드 - 백엔드 API 연동 완료
- [x] E2E 플로우 동작 확인

---

## 📅 Week 4: 통합 테스트 + 버그 수정 (11/25-12/1)

### 11/25-11/27 (3일): 전체 시스템 통합

```
□ 전체 플로우 테스트
  1. 프론트에서 뉴스 입력
  2. 백엔드가 AI 서버에 요청
  3. AI 서버가 스탠스 분석
  4. 백엔드가 결과 저장 및 반환
  5. 프론트에 결과 표시

□ 버그 리스트 작성
  - 크리티컬 버그 (기능 불가)
  - 중요 버그 (사용성 저하)
  - 마이너 버그 (UI 이슈 등)

□ 성능 테스트
  - 동시 요청 처리
  - 응답 시간 측정
  - 병목 구간 파악
```

**담당:** 전체 팀원

---

### 11/28-12/1 (4일): 버그 수정 및 최적화

```
□ 우선순위별 버그 수정
  - P0 (크리티컬): 즉시 수정
  - P1 (중요): 11/30까지 수정
  - P2 (마이너): 시간 있으면 수정

□ 성능 최적화
  - DB 쿼리 최적화
  - API 응답 시간 개선
  - 프론트 로딩 속도 개선

□ 사용성 개선
  - 에러 메시지 개선
  - 로딩 인디케이터 추가
  - 반응형 디자인 적용
```

**담당:** 각 파트별 담당자

---

### Week 4 목표 달성 기준 ✅

- [x] E2E 테스트 통과
- [x] 크리티컬 버그 0건
- [x] 중요 버그 최소화
- [x] 성능 기준 충족 (응답 시간 < 3초)

---

## 📅 Week 5: 시연 준비 + 발표 (12/2-12/15)

### 12/2-12/4 (3일): 최종 QA 및 데모 데이터 준비

```
□ 전체 기능 재테스트
  - 체크리스트 기반 테스트
  - 예외 케이스 테스트
  - 다양한 뉴스로 테스트

□ 데모 시나리오 작성
  - 실제 뉴스 5-10개 준비
  - 각 스탠스별 대표 사례
  - 예상 질문 Q&A 준비

□ 데모 데이터 DB 저장
  - 시연용 뉴스 미리 등록
  - 분석 결과 미리 저장
```

**담당:** 전체 팀원

---

### 12/5-12/8 (4일): 발표 자료 및 리허설

```
□ 12/5-12/6 (2일): 발표 자료 제작
  - PPT 제작
    1. 프로젝트 소개
    2. 기술 스택
    3. 주요 기능 (스탠스 분석)
    4. 데모 영상 or 라이브 시연
    5. 향후 계획

□ 12/7 (1일): 시연 스크립트 작성
  - 시연 순서 정리
  - 각 파트별 설명 분담
  - 예상 소요 시간: 10-15분

□ 12/8 (1일): 팀 내부 리허설
  - 전체 팀원 앞에서 발표 연습
  - 피드백 수렴 및 개선
  - 타이밍 조정
```

**담당:** 전체 팀원

---

### 12/9-12/14 (6일): Buffer 기간

```
□ 12/9-12/11 (3일): 최종 점검 및 수정
  - 발표 자료 수정
  - 시연 환경 점검
  - 백업 계획 수립 (인터넷 끊김 대비 등)

□ 12/12-12/14 (3일): 최종 리허설
  - 실제 발표장 환경에서 리허설
  - 시간 측정 (10-15분 준수)
  - 질의응답 연습
```

**담당:** 전체 팀원

---

### 12/15 (D-Day): 시연 및 발표 🎉

```
□ 오전: 최종 점검
  - 노트북, 프로젝터 연결 테스트
  - 인터넷 연결 확인
  - 백업 데모 영상 준비

□ 시연/발표
  1. 프로젝트 소개 (2분)
  2. 기술 설명 (3분)
  3. 라이브 시연 (5분)
  4. 향후 계획 (2분)
  5. Q&A (3분)

□ 시연 시나리오 예시:
  1. 뉴스 1 입력 → 옹호 분석 결과 표시
  2. 뉴스 2 입력 → 중립 분석 결과 표시
  3. 뉴스 3 입력 → 비판 분석 결과 표시
  4. 과거 분석 결과 목록 조회
```

**🎯 발표 성공 기준:**
- 전체 시스템 정상 동작
- 시연 성공 (최소 3개 뉴스 분석)
- 질의응답 대응 완료

---

## 📊 주간 체크포인트

| 날짜 | 체크 항목 | 담당 |
|------|----------|------|
| **11/10 (일)** | 6000개 라벨링 + 검수 완료 | 전체 |
| **11/17 (일)** | 모델 학습 완료 (75%+), 백엔드 기본 API 완료 | AI, 백엔드 |
| **11/24 (일)** | AI-백엔드-프론트 연동 완료 | 전체 |
| **12/1 (일)** | 통합 테스트 완료, 버그 수정 완료 | 전체 |
| **12/8 (일)** | 시연 준비 완료, 발표 자료 완료 | 전체 |
| **12/15 (일)** | 시연 및 발표 🎉 | 전체 |

---

## 🎯 우선순위 (반드시 완료)

### P0 (필수 - MVP)
1. ✅ 6000개 라벨링 (자동 + 검수)
2. ✅ KoBERT 모델 학습 (75% 이상)
3. ✅ AI 서버 스탠스 분석 API
4. ✅ 백엔드 뉴스 분석 요청/응답 API
5. ✅ 프론트 뉴스 입력 + 결과 표시

### P1 (중요 - 있으면 좋음)
- 분석 결과 목록 조회
- 스탠스별 필터링
- 신뢰도 시각화
- 반응형 디자인

### P2 (옵션 - 시간 있으면)
- 통계 대시보드
- 히스토리 관리
- 뉴스 북마크

---

## 💰 예상 비용 (자동 라벨링)

| 항목 | 예상 비용 |
|------|----------|
| **Gemini API** (6000개) | $2-5 (또는 무료 할당량) |
| **ChatGPT API** (옵션) | $5-10 |
| **교차 검증** (Both) | $7-15 |

**권장:** Gemini 무료 할당량 활용 → **$0-3**

---

## ⏱️ 시간 절약 요약

| 작업 | 기존 방법 | 자동 라벨링 | 절약 |
|------|----------|------------|------|
| 라벨링 | 30-40시간 | 1-2시간 | **95%** |
| 검수 | - | 3-4시간 | - |
| 총 데이터 준비 | 30-40시간 | 4-6시간 | **85%** |

**🎉 Week 1이 7일 → 2-3일로 단축!**

---

## 🚨 리스크 관리

| 리스크 | 확률 | 대응 방안 |
|--------|------|----------|
| **API 키 발급 지연** | 낮음 | 미리 발급 (11/4) |
| **자동 라벨링 품질 낮음** | 중간 | 프롬프트 튜닝 + 검수 강화 |
| **모델 성능 부족** | 중간 | 데이터 양 충분 (6000개) → 성공 가능성 높음 |
| **통합 오류** | 높음 | Week 4 전체를 통합에 할애 |

---

## 📝 다음 단계

1. **즉시 시작:**
   - API 키 발급 (Gemini, ChatGPT)
   - 뉴스 수집 시작

2. **11/6부터:**
   - 자동 라벨링 스크립트 실행
   - 샘플 10개로 테스트 후 전체 실행

3. **11/8-11/10:**
   - 팀원 분담하여 검수

---

**💪 화이팅! 12/15 시연 성공을 응원합니다!**
