"""
LLM ê¸°ë°˜ ìë™ ë¼ë²¨ë§ ìŠ¤í¬ë¦½íŠ¸ (ChatGPT + Gemini)

ì‚¬ìš©ë²•:
    # ChatGPTë¡œ ë¼ë²¨ë§
    python scripts/auto_labeling.py --input data/unlabeled.csv --output data/labeled.csv --provider openai --api-key YOUR_KEY

    # Geminië¡œ ë¼ë²¨ë§
    python scripts/auto_labeling.py --input data/unlabeled.csv --output data/labeled.csv --provider gemini --api-key YOUR_KEY

    # ë‘ API ë³‘í–‰ ì‚¬ìš© (êµì°¨ ê²€ì¦)
    python scripts/auto_labeling.py --input data/unlabeled.csv --output data/labeled.csv --provider both --openai-key KEY1 --gemini-key KEY2
"""

import argparse
import pandas as pd
import json
import time
import os
from typing import Dict, List, Optional
from tqdm.auto import tqdm


# ============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ============================================================================

STANCE_LABELING_PROMPT = """ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë…¼ì¡°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì½ê³ , ê¸°ì‚¬ì˜ ë…¼ì¡°(ìŠ¤íƒ ìŠ¤)ë¥¼ ë‹¤ìŒ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

**0: ì˜¹í˜¸ (Support)**
- íŠ¹ì • ì´ìŠˆ, ì •ì±…, ì¸ë¬¼ì— ëŒ€í•´ ê¸ì •ì ì´ê³  ì§€ì§€í•˜ëŠ” ë…¼ì¡°
- ê¸ì •ì  í‘œí˜„ ì‚¬ìš©, ì´ì ê³¼ ê¸°ëŒ€ íš¨ê³¼ ê°•ì¡°
- ì˜ˆì‹œ: "ì´ë²ˆ ì •ì±…ì€ ê²½ì œ ì„±ì¥ì— í° ë„ì›€ì´ ë  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤."

**1: ì¤‘ë¦½ (Neutral)**
- íŠ¹ì • ì…ì¥ì„ ì·¨í•˜ì§€ ì•Šê³  ì‚¬ì‹¤ë§Œì„ ì „ë‹¬í•˜ëŠ” ì¤‘ë¦½ì  ë…¼ì¡°
- ê°ì •ì  í‘œí˜„ ì—†ì´ ê°ê´€ì  ì„œìˆ , ì–‘ì¸¡ ì˜ê²¬ ê· í˜•ìˆê²Œ ì œì‹œ
- ì˜ˆì‹œ: "ì •ë¶€ê°€ ìƒˆë¡œìš´ ì •ì±…ì„ ë°œí‘œí–ˆë‹¤. ì‹œí–‰ ì‹œê¸°ëŠ” ë‚´ë…„ ì´ˆë¡œ ì˜ˆì •ë˜ì–´ ìˆë‹¤."

**2: ë¹„íŒ (Oppose)**
- íŠ¹ì • ì´ìŠˆ, ì •ì±…, ì¸ë¬¼ì— ëŒ€í•´ ë¶€ì •ì ì´ê³  ë¹„íŒí•˜ëŠ” ë…¼ì¡°
- ë¶€ì •ì  í‘œí˜„ ì‚¬ìš©, ë¬¸ì œì ê³¼ ìš°ë ¤ì‚¬í•­ ê°•ì¡°
- ì˜ˆì‹œ: "ì •ë¶€ì˜ ì •ì±…ì€ í˜„ì‹¤ì„ ì œëŒ€ë¡œ ë°˜ì˜í•˜ì§€ ëª»í•œ ì±„ ì¡¸ì†ìœ¼ë¡œ ì¶”ì§„ë˜ê³  ìˆë‹¤."

---

**ë‰´ìŠ¤ ê¸°ì‚¬:**
{text}

---

**ì¤‘ìš”:**
1. ê¸°ì‚¬ ì „ì²´ì˜ ë…¼ì¡°ë¥¼ íŒŒì•…í•˜ì„¸ìš” (ì œëª©ë§Œ ë³´ì§€ ë§ê³  ì „ì²´ ë§¥ë½ ê³ ë ¤)
2. ê¸°ìì˜ ì˜ê²¬ vs ì¸ìš©ë¬¸ì„ êµ¬ë¶„í•˜ì„¸ìš”
3. ì• ë§¤í•œ ê²½ìš° ì¤‘ë¦½(1)ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”
4. ë°˜ë“œì‹œ 0, 1, 2 ì¤‘ í•˜ë‚˜ì˜ ìˆ«ìë§Œ ë‹µë³€í•˜ì„¸ìš”

**ë‹µë³€ í˜•ì‹ (JSON):**
{{
  "label": 0 ë˜ëŠ” 1 ë˜ëŠ” 2,
  "confidence": 0.0~1.0 (í™•ì‹ ë„),
  "reason": "íŒë‹¨ ê·¼ê±°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ"
}}
"""


# ============================================================================
# API í´ë¼ì´ì–¸íŠ¸
# ============================================================================

class LabelingClient:
    """LLM ê¸°ë°˜ ë¼ë²¨ë§ í´ë¼ì´ì–¸íŠ¸ (ì¶”ìƒ í´ë˜ìŠ¤)"""

    def __init__(self, api_key: str, model: str):
        self.api_key = api_key
        self.model = model
        self.cost = 0.0
        self.request_count = 0

    def label_text(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ ë¼ë²¨ë§ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        raise NotImplementedError

    def _parse_response(self, response_text: str) -> Dict:
        """ì‘ë‹µ íŒŒì‹±"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            result = json.loads(response_text)

            # ìœ íš¨ì„± ê²€ì¦
            if "label" not in result:
                return {"error": "label í•„ë“œ ëˆ„ë½"}

            label = int(result["label"])
            if label not in [0, 1, 2]:
                return {"error": f"ì˜ëª»ëœ ë ˆì´ë¸” ê°’: {label}"}

            return {
                "label": label,
                "confidence": float(result.get("confidence", 0.5)),
                "reason": result.get("reason", "")
            }
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìˆ«ìë§Œ ì¶”ì¶œ ì‹œë„
            import re
            numbers = re.findall(r'\b[012]\b', response_text)
            if numbers:
                return {
                    "label": int(numbers[0]),
                    "confidence": 0.5,
                    "reason": "JSON íŒŒì‹± ì‹¤íŒ¨, ìˆ«ìë§Œ ì¶”ì¶œ"
                }
            return {"error": f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {response_text[:100]}"}


class OpenAIClient(LabelingClient):
    """OpenAI (ChatGPT) í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        super().__init__(api_key, model)
        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=api_key)
        except ImportError:
            raise ImportError("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openai")

    def label_text(self, text: str) -> Dict:
        """ChatGPTë¡œ ë¼ë²¨ë§"""
        try:
            prompt = STANCE_LABELING_PROMPT.format(text=text)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë…¼ì¡° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=200
            )

            self.request_count += 1

            # ë¹„ìš© ê³„ì‚° (gpt-4o-mini ê¸°ì¤€: input $0.15/1M tokens, output $0.6/1M tokens)
            if self.model == "gpt-4o-mini":
                input_cost = response.usage.prompt_tokens / 1_000_000 * 0.15
                output_cost = response.usage.completion_tokens / 1_000_000 * 0.6
                self.cost += input_cost + output_cost

            response_text = response.choices[0].message.content
            result = self._parse_response(response_text)
            result["provider"] = "openai"
            result["model"] = self.model

            return result

        except Exception as e:
            return {"error": f"OpenAI API ì˜¤ë¥˜: {str(e)}"}


class GeminiClient(LabelingClient):
    """Google Gemini í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: str, model: str = "gemini-1.5-flash"):
        super().__init__(api_key, model)
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            self.client = genai.GenerativeModel(model)
        except ImportError:
            raise ImportError("google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install google-generativeai")

    def label_text(self, text: str) -> Dict:
        """Geminië¡œ ë¼ë²¨ë§"""
        try:
            import google.generativeai as genai
            prompt = STANCE_LABELING_PROMPT.format(text=text)

            # ì•ˆì „ í•„í„° ì„¤ì • (ì •ì¹˜ ë‰´ìŠ¤ ë¶„ì„ì„ ìœ„í•´ ì™„í™”)
            safety_settings = {
                genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: genai.types.HarmBlockThreshold.BLOCK_NONE,
                genai.types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: genai.types.HarmBlockThreshold.BLOCK_NONE,
            }

            response = self.client.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.1,
                    "max_output_tokens": 200,
                },
                safety_settings=safety_settings
            )

            self.request_count += 1

            # ë¹„ìš© ê³„ì‚° (Gemini 1.5 Flash: input $0.075/1M tokens, output $0.3/1M tokens)
            # ì°¸ê³ : ì •í™•í•œ í† í° ìˆ˜ëŠ” response.usage_metadataì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ
            if hasattr(response, 'usage_metadata'):
                input_cost = response.usage_metadata.prompt_token_count / 1_000_000 * 0.075
                output_cost = response.usage_metadata.candidates_token_count / 1_000_000 * 0.3
                self.cost += input_cost + output_cost

            response_text = response.text
            result = self._parse_response(response_text)
            result["provider"] = "gemini"
            result["model"] = self.model

            return result

        except Exception as e:
            return {"error": f"Gemini API ì˜¤ë¥˜: {str(e)}"}


# ============================================================================
# ìë™ ë¼ë²¨ë§ ë©”ì¸ ë¡œì§
# ============================================================================

class AutoLabeler:
    """ìë™ ë¼ë²¨ë§ í´ë˜ìŠ¤"""

    def __init__(self, clients: List[LabelingClient], save_interval: int = 50):
        self.clients = clients
        self.save_interval = save_interval
        self.results = []

    def label_dataset(self, df: pd.DataFrame, text_column: str = "text") -> pd.DataFrame:
        """ë°ì´í„°ì…‹ ì „ì²´ ë¼ë²¨ë§"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤– ìë™ ë¼ë²¨ë§ ì‹œì‘")
        print(f"{'='*60}")
        print(f"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}ê°œ")
        print(f"ì‚¬ìš© API: {[c.__class__.__name__ for c in self.clients]}")
        print(f"{'='*60}\n")

        labeled_data = []

        for idx, row in tqdm(df.iterrows(), total=len(df), desc="ë¼ë²¨ë§ ì¤‘"):
            text = row[text_column]

            # ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ë¡œ ë¼ë²¨ë§ (êµì°¨ ê²€ì¦ìš©)
            labels = []
            confidences = []
            reasons = []
            providers = []

            for client in self.clients:
                result = client.label_text(text)

                if "error" in result:
                    print(f"\nâš ï¸  ì˜¤ë¥˜ ë°œìƒ (í–‰ {idx}): {result['error']}")
                    continue

                labels.append(result["label"])
                confidences.append(result.get("confidence", 0.5))
                reasons.append(result.get("reason", ""))
                providers.append(result.get("provider", "unknown"))

                # API Rate Limit ë°©ì§€
                time.sleep(0.5)

            if not labels:
                print(f"\nâŒ ëª¨ë“  API ì‹¤íŒ¨ (í–‰ {idx})")
                continue

            # ë¼ë²¨ ì§‘ê³„
            if len(labels) == 1:
                final_label = labels[0]
                final_confidence = confidences[0]
                agreement = True
            else:
                # ì—¬ëŸ¬ API ì‚¬ìš© ì‹œ: ê³¼ë°˜ìˆ˜ íˆ¬í‘œ
                from collections import Counter
                label_counts = Counter(labels)
                final_label = label_counts.most_common(1)[0][0]
                final_confidence = sum(confidences) / len(confidences)
                agreement = all(l == final_label for l in labels)

            labeled_data.append({
                **row.to_dict(),
                "label": final_label,
                "confidence": round(final_confidence, 4),
                "agreement": agreement,
                "providers": ",".join(providers),
                "reasons": " | ".join(reasons) if reasons else ""
            })

            # ì¤‘ê°„ ì €ì¥
            if len(labeled_data) % self.save_interval == 0:
                self._save_checkpoint(labeled_data, f"checkpoint_{len(labeled_data)}.csv")

        result_df = pd.DataFrame(labeled_data)

        # í†µê³„ ì¶œë ¥
        self._print_statistics(result_df)

        return result_df

    def _save_checkpoint(self, data: List[Dict], filename: str):
        """ì¤‘ê°„ ì €ì¥"""
        checkpoint_dir = "data/checkpoints"
        os.makedirs(checkpoint_dir, exist_ok=True)
        filepath = os.path.join(checkpoint_dir, filename)
        pd.DataFrame(data).to_csv(filepath, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {filepath}")

    def _print_statistics(self, df: pd.DataFrame):
        """í†µê³„ ì¶œë ¥"""
        print(f"\n\n{'='*60}")
        print(f"ğŸ“Š ë¼ë²¨ë§ ì™„ë£Œ í†µê³„")
        print(f"{'='*60}")

        print(f"\nì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}ê°œ")

        # ë ˆì´ë¸” ë¶„í¬
        label_names = {0: 'ì˜¹í˜¸', 1: 'ì¤‘ë¦½', 2: 'ë¹„íŒ'}
        print(f"\në ˆì´ë¸” ë¶„í¬:")
        for label in [0, 1, 2]:
            count = (df['label'] == label).sum()
            percentage = count / len(df) * 100 if len(df) > 0 else 0
            print(f"  {label} ({label_names[label]}): {count}ê°œ ({percentage:.1f}%)")

        # ì‹ ë¢°ë„ í†µê³„
        if 'confidence' in df.columns:
            print(f"\nì‹ ë¢°ë„ í†µê³„:")
            print(f"  í‰ê· : {df['confidence'].mean():.3f}")
            print(f"  ì¤‘ê°„ê°’: {df['confidence'].median():.3f}")
            print(f"  ìµœì†Œ: {df['confidence'].min():.3f}")
            print(f"  ìµœëŒ€: {df['confidence'].max():.3f}")

        # ì¼ì¹˜ë„ (ì—¬ëŸ¬ API ì‚¬ìš© ì‹œ)
        if 'agreement' in df.columns:
            agreement_rate = df['agreement'].sum() / len(df) * 100
            print(f"\nAPI ê°„ ì¼ì¹˜ë„: {agreement_rate:.1f}%")

        # ë¹„ìš© í†µê³„
        print(f"\nAPI ì‚¬ìš© í†µê³„:")
        for client in self.clients:
            print(f"  {client.__class__.__name__}:")
            print(f"    ìš”ì²­ ìˆ˜: {client.request_count}íšŒ")
            print(f"    ì˜ˆìƒ ë¹„ìš©: ${client.cost:.4f}")

        total_cost = sum(c.cost for c in self.clients)
        print(f"\nì´ ì˜ˆìƒ ë¹„ìš©: ${total_cost:.4f}")

        print(f"{'='*60}\n")


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='LLM ê¸°ë°˜ ìë™ ë¼ë²¨ë§')
    parser.add_argument('--input', type=str, required=True, help='ì…ë ¥ CSV íŒŒì¼')
    parser.add_argument('--output', type=str, required=True, help='ì¶œë ¥ CSV íŒŒì¼')
    parser.add_argument('--text-column', type=str, default='text', help='í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì´ë¦„')
    parser.add_argument('--provider', type=str, choices=['openai', 'gemini', 'both'], default='openai',
                        help='ì‚¬ìš©í•  API: openai, gemini, both')
    parser.add_argument('--openai-key', type=str, help='OpenAI API í‚¤')
    parser.add_argument('--gemini-key', type=str, help='Gemini API í‚¤')
    parser.add_argument('--openai-model', type=str, default='gpt-4o-mini', help='OpenAI ëª¨ë¸')
    parser.add_argument('--gemini-model', type=str, default='gemini-1.5-flash', help='Gemini ëª¨ë¸')
    parser.add_argument('--save-interval', type=int, default=50, help='ì¤‘ê°„ ì €ì¥ ê°„ê²©')
    parser.add_argument('--sample', type=int, help='í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ê°œìˆ˜')

    args = parser.parse_args()

    # ë°ì´í„° ë¡œë“œ
    print(f"\n[INFO] Loading data: {args.input}")
    df = pd.read_csv(args.input)

    if args.sample:
        print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²« {args.sample}ê°œë§Œ ë¼ë²¨ë§")
        df = df.head(args.sample)

    print(f"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}ê°œ\n")

    # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    clients = []

    if args.provider in ['openai', 'both']:
        if not args.openai_key:
            print("âŒ --openai-key í•„ìˆ˜")
            return
        print(f"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ëª¨ë¸: {args.openai_model})")
        clients.append(OpenAIClient(args.openai_key, args.openai_model))

    if args.provider in ['gemini', 'both']:
        if not args.gemini_key:
            print("âŒ --gemini-key í•„ìˆ˜")
            return
        print(f"âœ… Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ëª¨ë¸: {args.gemini_model})")
        clients.append(GeminiClient(args.gemini_key, args.gemini_model))

    # ìë™ ë¼ë²¨ë§
    labeler = AutoLabeler(clients, save_interval=args.save_interval)
    result_df = labeler.label_dataset(df, text_column=args.text_column)

    # ê²°ê³¼ ì €ì¥
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    result_df.to_csv(args.output, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ë¼ë²¨ë§ ì™„ë£Œ: {args.output}")

    print(f"\në‹¤ìŒ ë‹¨ê³„:")
    print(f"1. ì‹ ë¢°ë„ê°€ ë‚®ì€ ìƒ˜í”Œ ê²€ìˆ˜ (confidence < 0.7)")
    print(f"2. API ê°„ ë¶ˆì¼ì¹˜ ìƒ˜í”Œ ê²€ìˆ˜ (agreement = False)")
    print(f"3. ê²€ì¦ ì™„ë£Œ í›„ ëª¨ë¸ í•™ìŠµ")


if __name__ == '__main__':
    main()
