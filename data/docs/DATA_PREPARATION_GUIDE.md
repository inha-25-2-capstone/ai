# 스탠스 분류 모델 학습 데이터 준비 가이드

## 개요

KoBERT 기반 뉴스 스탠스 분류 모델을 학습하기 위한 데이터 준비 가이드입니다.

## 데이터 형식

### CSV 형식

```csv
text,label
"정부의 새로운 경제 정책은 경제 성장을 촉진하고 일자리를 창출할 것으로 기대된다.",0
"정부가 새로운 정책을 발표했다. 정책의 주요 내용은 경제 활성화와 일자리 창출이다.",1
"정부의 정책은 현실을 제대로 반영하지 못한 채 졸속으로 추진되고 있다.",2
```

### JSON 형식

```json
[
  {
    "text": "정부의 새로운 경제 정책은 경제 성장을 촉진하고 일자리를 창출할 것으로 기대된다.",
    "label": 0
  },
  {
    "text": "정부가 새로운 정책을 발표했다. 정책의 주요 내용은 경제 활성화와 일자리 창출이다.",
    "label": 1
  },
  {
    "text": "정부의 정책은 현실을 제대로 반영하지 못한 채 졸속으로 추진되고 있다.",
    "label": 2
  }
]
```

## 레이블 정의

| 레이블 | 스탠스 | 설명 |
|--------|--------|------|
| 0 | 옹호 (Support) | 특정 이슈, 정책, 인물에 대해 긍정적이고 지지하는 논조 |
| 1 | 중립 (Neutral) | 특정 입장을 취하지 않고 사실만을 전달하는 중립적 논조 |
| 2 | 비판 (Oppose) | 특정 이슈, 정책, 인물에 대해 부정적이고 비판하는 논조 |

## 라벨링 가이드라인

### 1. 옹호 (Support) - 레이블 0

**특징:**
- 긍정적인 어조와 표현 사용
- 이점과 기대 효과 강조
- 성공 사례와 긍정적 전망 제시
- 찬성하는 전문가 의견 인용

**예시:**
```
✅ "이번 정책은 경제 발전에 큰 도움이 될 것으로 기대된다."
✅ "전문가들은 이번 조치가 시의적절하다고 평가했다."
✅ "정책 시행 후 관련 업계의 매출이 증가하고 있다."
```

### 2. 중립 (Neutral) - 레이블 1

**특징:**
- 감정적 표현 없이 사실만 전달
- 양쪽 의견을 균형있게 제시
- 통계와 사실 중심의 서술
- "~했다", "~이다" 등 단순 서술형

**예시:**
```
✅ "정부가 새로운 정책을 발표했다. 시행 시기는 내년 초로 예정되어 있다."
✅ "이번 개혁안에 대해 전문가들의 의견이 엇갈리고 있다."
✅ "정책 발표 후 관련 업계에서는 다양한 반응이 나오고 있다."
```

### 3. 비판 (Oppose) - 레이블 2

**특징:**
- 부정적인 어조와 표현 사용
- 문제점과 우려사항 강조
- 실패 가능성과 부작용 경고
- 비판하는 전문가 의견 인용

**예시:**
```
✅ "이번 정책은 현실을 제대로 반영하지 못했다."
✅ "전문가들은 부작용을 우려하고 있다."
✅ "업계는 강력히 반발하고 있다."
```

## 라벨링 주의사항

### ⚠️ 주의할 점

1. **제목만으로 판단하지 말 것**
   - 전체 기사 본문을 읽고 판단
   - 제목은 클릭을 유도하기 위해 과장될 수 있음

2. **기자의 의견 vs 인용문 구분**
   - 기사 전체의 논조를 파악
   - 단순 인용문이 아닌 기사의 전체적인 맥락 고려

3. **복합적인 논조 처리**
   - 긍정과 부정이 섞여 있다면 전체적인 무게 중심으로 판단
   - 애매한 경우 중립으로 분류

4. **특정 토픽에 대한 일관성**
   - 같은 이슈에 대해서는 일관된 기준 적용
   - 토픽별로 기준이 다르면 모델 학습에 혼란

## 데이터 품질 체크리스트

### 데이터 수집 전

- [ ] 다양한 언론사의 기사 포함
- [ ] 특정 토픽에 대해 다양한 논조 포함
- [ ] 최소 토픽당 30개 이상의 기사 수집
- [ ] 옹호/중립/비판 비율이 심하게 불균형하지 않은지 확인

### 라벨링 중

- [ ] 2명 이상의 라벨러가 독립적으로 라벨링
- [ ] 불일치 샘플은 토론을 통해 합의
- [ ] 애매한 샘플은 별도로 표시하고 나중에 재검토

### 라벨링 후

- [ ] 각 클래스당 최소 100개 이상의 샘플 확보
- [ ] 클래스 불균형이 심하지 않은지 확인 (최대/최소 비율 3:1 이하 권장)
- [ ] 랜덤 샘플링으로 품질 검증
- [ ] 중복 제거

## 권장 데이터 규모

| 단계 | 최소 데이터 수 | 권장 데이터 수 | 클래스당 최소 |
|------|----------------|----------------|---------------|
| 프로토타입 | 300개 | 500개 | 100개 |
| 베타 버전 | 1,000개 | 2,000개 | 300개 |
| 프로덕션 | 3,000개 | 10,000개 | 1,000개 |

## 데이터 분할 비율

- **학습(Train)**: 70%
- **검증(Validation)**: 10%
- **테스트(Test)**: 20%

노트북에서 자동으로 분할되므로 전체 데이터만 준비하면 됩니다.

## 샘플 데이터셋 구조

```
data/
├── DATA_PREPARATION_GUIDE.md  # 이 파일
├── train_data.csv              # 학습용 데이터
├── train_data.json             # 또는 JSON 형식
└── sample_data.csv             # 테스트용 샘플 데이터
```

## 데이터 업로드 방법

### Colab에서 업로드

1. 노트북의 "2. 데이터 준비" 섹션에서 `USE_REAL_DATA = True`로 변경
2. 셀 실행 시 파일 업로드 버튼 클릭
3. CSV 또는 JSON 파일 선택

### GitHub에서 직접 로드

```python
import pandas as pd

# CSV 로드
df = pd.read_csv('https://raw.githubusercontent.com/your-repo/ai/main/data/train_data.csv')

# JSON 로드
df = pd.read_json('https://raw.githubusercontent.com/your-repo/ai/main/data/train_data.json')
```

## 데이터 검증

데이터를 준비한 후 다음 코드로 검증할 수 있습니다:

```python
import pandas as pd

# 데이터 로드
df = pd.read_csv('train_data.csv')

# 기본 정보
print(f"전체 샘플 수: {len(df)}")
print(f"\n컬럼: {df.columns.tolist()}")
print(f"\n결측치:\n{df.isnull().sum()}")

# 클래스 분포
print(f"\n클래스별 분포:")
print(df['label'].value_counts().sort_index())

# 레이블 값 확인 (0, 1, 2만 있어야 함)
unique_labels = df['label'].unique()
print(f"\n고유 레이블 값: {sorted(unique_labels)}")
assert set(unique_labels).issubset({0, 1, 2}), "레이블 값이 0, 1, 2가 아닌 값이 있습니다!"

# 텍스트 길이 통계
df['text_length'] = df['text'].str.len()
print(f"\n텍스트 길이 통계:")
print(df['text_length'].describe())

# 샘플 확인
print(f"\n샘플 데이터:")
print(df.head())
```

## 추가 리소스

- [KoBERT GitHub](https://github.com/SKTBrain/KoBERT)
- [스탠스 탐지 관련 논문](https://arxiv.org/abs/1606.03784)
- [프로젝트 README](../README.md)

## 문의

데이터 라벨링 중 궁금한 점이 있으면 팀에 문의하세요.
